[{"id":"a151887ec11ae6391c8864d43efe6e8e","title":"分布式和微服务的区别","content":"1.分布式和微服务有什么区别呢？分布式的核心就一个字：拆。只要是将一个项目拆分成了多个模块，并将这些模块分开部署，那就算是分布式。\n如何拆呢？有两种方式：水平拆分，或垂直拆分（也称为“横向拆分”和“垂直拆分”），具体如下：\n水平拆分：根据“分层”的思想进行拆分。例如，可以将一个项目根据“三层架构”拆分成 表示层（jsp+servlet）、业务逻辑层（service）和数据访问层（dao），然后再分开部署：把表示层部署在服务器A上，把service和dao层部署在服务器B上，然后服务器A和服务器B之间通过dubbo等RPC进行进行整合（在左下角的“阅读原文”里有dubbo的视频课程，可以点击学习），如图所示。\n垂直拆分：根据业务进行拆分。例如，可以根据业务逻辑，将“电商项目”拆分成“订单项目”、“用户项目”和“秒杀项目”。显然这三个拆分后的项目，仍然可以作为独立的项目使用。像这种拆分的方法，就成为垂直拆分。\n什么是微服务呢？\n从名字就能知道，“微服务”就是非常微小的服务。\n微服务可以理解为一种非常细粒度的垂直拆分。例如，以上“订单项目”本来就是垂直拆分后的子项目，但实际上“订单项目”还能进一步拆分为“购物项目”、“结算项目”和“售后项目”，如图。\n现在看图中的“订单项目”，它完全可以作为一个分布式项目的组成元素，但就不适合作为微服务的组成元素了（因为它还能再拆，而微服务应该是不能再拆的“微小”服务，类似于“原子性”）。\n总结：\n分布式：拆了就行。\n微服务：细粒度的垂直拆分。\n2.Java中不是有GC吗，怎么还有内存泄漏一说？答：Java内存有两种常见问题：内存溢出和内存泄漏。\n内存溢出好理解，就是JVM内存有限。如果对象太多，JVM内存放不下了，就会内存溢出。\n那什么是内存泄漏？首先得明确，GC只会回收那些“不可达”的对象（可以简单理解为，如果一个对象存在着指向它的引用，这个对象就“可达”；如果没有引用指向它，则“不可达”）。\n若一个对象是“无用但可达的”，就会造成内存泄漏。\n如下代码中，obj的值是null，因此是“无用的”；但同时obj又同时被被list引用，因此是“可达”的，所以此时的obj就会造成内存泄漏。\nObject obj &#x3D; new Object();\n\nlist.add( obj );\nobj &#x3D; null ;\n除了上面obj这种内存泄漏的情况以外，在实际开发中最常见的内存泄漏就是打开资源后没有调用close()方法。例如socket、io流等，都需要再最后close()一下防止内存泄漏。\n","slug":"attribute","date":"2023-03-28T06:20:55.000Z","categories_index":"","tags_index":"service","author_index":"Sh1mwww"},{"id":"e59b750bc82711213370e958d83d7a80","title":"Nginx攻击方式和解决方案","content":"3分钟了解 NginxNginx是一款高性能的Web服务器和反向代理服务器。\n它可以用来搭建网站、做应用服务器，能够处理大量的并发连接和请求。\n\n静态内容托管（主要）：可以用来做网页、图片、文件的 “静态”内容托管。\n动态内容托管（主要）：将经常访问的动态内容缓存到内存中，提高访问速度和性能。\n反向代理（主要）：将客户端的请求发送到后端真实服务器，并将后端服务器的响应返回给客户端。\n\n*类似于一个快递收发室，指挥快递（流量）应该投递到哪个买家。\n它还能提供一些高级功能：\n\n负载均衡：将客户端的请求分发到多个后端服务器上，从而提高服务的可用性和性能。\nSSL&#x2F;TLS加密传输：通过加密和认证保护数据传输安全。\nHTTP&#x2F;2支持：通过多路复用技术提高并发连接处理能力和页面加载速度。\n安全防护：提供多种防护机制，如限制IP访问、请求频率限制、反爬虫等。\n动态内容处理：支持FastCGI、uWSGI等协议，与后端应用服务器进行动态内容交互。\n日志记录：记录访问日志和错误日志，方便监控和排查问题。\n自定义模块开发：支持自定义模块开发，可以根据需求进行二次开发和扩展。读到这里，我知道很多人脑子都要爆了。现在让我们直入主题。结合以上功能的能做哪些攻击方式。\n\n反向代理攻击使用Nginx作为反向代理服务器，将攻击流量转发到目标服务器。这样就能隐藏攻击流量的真实地址。\nserver &#123;\n    listen 80;\n    server_name www.example.com;\n    location &#x2F; &#123;\n        proxy_pass http:&#x2F;&#x2F;backend_server;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    &#125;\n&#125;\n\n所有访问www.example.com:80的流量全部都会转发到http://backend_server服务器上。\nproxy_set_header X-Real-IP $remote_addr; 设置请求头提供真实来源ip。\nproxy_set_header Host $host;设置访问的Host。\n\n只要把X-Real-IP改成其他不存在的IP，就可以隐藏自己的真实IP地址，让攻击更难以被追踪和防御。当然相对于客户端来说，只能知道nginx的地址就不知道真实服务器的地址了。\nDDoS攻击DDoS攻击就是借助某些工具瞬间发动大量的请求，让服务器资源耗尽，无法正常响应其他用户的请求，一般也常用于压力测试。介绍一些常用的工具：\n\n**ApacheBench (ab)**：常用的命令行工具，用于模拟多个并发请求。可以控制请求总数、并发数等参数。\nSiege：命令行工具，和上面一样，并且还支持 HTTP和HTTPS协议。\nJMeter：一个功能强大的Java应用程序，可以用于模拟各种负载情况.JMeter可以通过图形界面进行配置，支持更多协议和数据格式，包括 HTTP、HTTPS、SOAP、REST 等。但事实往往比这个残酷，攻击者会做一些病毒，在网络上传播开来，病毒运行时可以直接疯狂访问服务器，或者利用Nginx提供的反向代理和其支持的比如socket、SSL，不断的建立握手请求。\n\n限流、黑名单防御主要给大家介绍怎么防御。这种病毒感染方式就不说了，我害怕戴银手铐。\nhttp &#123;\n    limit_req_zone $binary_remote_addr zone&#x3D;one:10m rate&#x3D;5r&#x2F;s;\n\n    geo $block &#123;\n        default 0;\n        include &#x2F;path&#x2F;to&#x2F;block_ip.txt;\n    &#125;\n\n    server &#123;\n        listen 80;\n\n        location &#x2F; &#123;\n            limit_req zone&#x3D;one burst&#x3D;10 nodelay;\n            if ($block) &#123;\n                return 403;\n            &#125;\n            proxy_pass http:&#x2F;&#x2F;backend;\n        &#125;\n    &#125;\n&#125;\n\nlimit_req_zone定义了一个名为“one”的限制请求速率的区域，该区域的大小为10MB，请求速率限制为每秒5个请求。\nlimit_req指定使用名为“one”的限制规则。\ngeo $block是黑名单，这个文件可以写需要屏蔽的ip。\nserver块中的location指令使用了limit_req和if表示黑名单的返回403状态码。\n\n负载均衡防御假设我有两个后端服务器。\nhttp &#123;\n  upstream backend &#123;\n    # 轮询方式的负载均衡\n    server backend1.example.com;\n    server backend2.example.com;\n  &#125;\n...\n  server&#123;...&#125;\n&#125;\n有多种负载均衡方式。\nserver &#123;\n  ...\n   location &#x2F;api&#x2F; &#123;\n     # 轮训\n     proxy_pass http:&#x2F;&#x2F;backend;\n   &#125;\n\n   location &#x2F;lb&#x2F; &#123;\n     # IP哈希方式的负载均衡\n     ip_hash;\n     proxy_pass http:&#x2F;&#x2F;backend;\n   &#125;\n\n   location &#x2F;upstream&#x2F; &#123;\n     # 根据服务器性能或响应时间进行加权轮询\n     upstream backend &#123;\n       server backend1.example.com weight&#x3D;2;\n       server backend2.example.com;\n     &#125;\n     # 对 backend 进行访问\n     proxy_pass http:&#x2F;&#x2F;backend;\n   &#125;\n\n   location &#x2F;least_conn&#x2F; &#123;\n     # 最少连接数的负载均衡\n     least_conn;\n     proxy_pass http:&#x2F;&#x2F;backend;\n   &#125;\n\n   location &#x2F;random&#x2F; &#123;\n     # 随机方式的负载均衡\n     random;\n     proxy_pass http:&#x2F;&#x2F;backend;\n   &#125;\n\n   location &#x2F;sticky&#x2F; &#123;\n     # 基于客户端IP的哈希方式的负载均衡\n     hash $remote_addr consistent;\n     server backend1.example.com;\n     server backend2.example.com;\n   &#125;\n &#125;\n很多人学nginx都会对ip_hash和基于客户端IP的哈希方式的负载均衡有疑惑。分不清，我一句话给大家讲清楚。\n\nip_hash能保证相同来源一定能访问相同的服务器，适用于登录等有状态的场景。在请求量少的时候，容易出现很多ip落在同一服务器上，分布不均衡。\n基于客户端ip的hash，是根据客户端 IP 地址计算哈希值，然后将哈希值与后端服务器数量取模。使请求平均分配到不同的服务器上，也能保证同一ip请求落到同一服务器上。但是可以保证各个服务器比较均衡。我认为使用方式二更好，可能理解有限，欢迎各位读者分享自己的看法！\n\n网络钓鱼攻击黑客可以使用Nginx伪装成一个合法的网站，诱骗用户输入敏感信息。例如，他们可以使用Nginx构造一个伪造的登录页面，让用户输入用户名和密码，然后将这些信息发送给黑客服务器。\n其实就是静态托管+反向代理功能的组合。\nserver &#123;\n    listen       80;\n    server_name  example.com;\n\n    # 静态网站托管\n    location &#x2F; &#123;\n        root   &#x2F;var&#x2F;www&#x2F;mywebsite&#x2F;dist;\n        index  index.html index.htm;\n    &#125;\n\n    # API代理转发\n    location &#x2F;api &#123;\n        proxy_pass  http:&#x2F;&#x2F;localhost:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    &#125;\n&#125;\n访问根目录就访问到静态的网站资源。访问&#x2F;api路由转发到api服务上。\n","slug":"nginx-attact","date":"2023-03-28T05:46:26.000Z","categories_index":"","tags_index":"nginx","author_index":"Sh1mwww"},{"id":"6d1c99c12c344c631fb3ed115b7df580","title":"如何使用Docker部署一个go程序","content":"Docker定义Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows操作系统的机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。\n本文我们介绍怎么使用 Docker 部署 Go 项目。阅读本文，需要读者朋友们了解 Docker 的基本操作。\ngo项目的开发首先，我们开发一个简单的 Go Web 项目，使用 Go 内置命令行工具 go build 编译生成可执行文件 .&#x2F;hello。这是项目结构\n.\n├── Dockerfile\n├── go.mod\n├── hello\n├── main.go\n└── service.log\n我们使用 Go 标准库编写一个 Web 项目，运行编译生成的可执行程序，访问 http://127.0.0.1:8080/hello，输出 hello word。\ncurl http:&#x2F;&#x2F;127.0.0.1:8080&#x2F;hello\n# 输出\nhello world\nDocker的使用我们开始编写 Dockerfile 文件，使该项目可以支持使用 Docker 部署。\nDockerfile 文件：\n# 基础镜像\nFROM alpine:3.12\n# 维护者\nMAINTAINER frank\n# docker build 时执行命令 - 创建目录\nRUN mkdir -p &quot;&#x2F;data&#x2F;app&quot; \\\n&amp;&amp; ln -sf &#x2F;dev&#x2F;stdout &#x2F;data&#x2F;app&#x2F;service.log\n# 工作目录\nWORKDIR &quot;&#x2F;data&#x2F;app&quot;\n# 拷贝\nCOPY hello &#x2F;data&#x2F;app&#x2F;hello\n# docker run 时执行命令\nENTRYPOINT [&quot;.&#x2F;hello&quot;]\n在编写完 Dockerfile 文件之后，我们可以使用 docker 命令构建镜像，前提是我们本机已安装 Docker。\ndocker build -t hello:v1.0.0 .\n运行以上构建 Docker 镜像的命令之后，我们就已成功构建 Docker 镜像。\n","slug":"docker-go","date":"2023-03-12T07:30:59.000Z","categories_index":"","tags_index":"docker,golang","author_index":"Sh1mwww"},{"id":"5af57275e38843538bce4be83af3cccf","title":"理解 ES 查询机制","content":"为什么需要使用 ES 进行搜索ES除了拥有索引上的优势，最重要的还是数据的结构，这都是ES为什么效率高，会使用它的原因。\n1，结构化数据 VS 非结构化数据\n结构化数据：  也称作行数据，关系型数据库进行存储和管理,是由二维表结构来逻辑表达和实现(可以使用行、列来表现)的数据，严格地遵循数据格式与长度规范。\n非结构化数据：  又可称为全文数据，不定长或无固定格式，不适于由数据库二维表来表现，包括所有格式的办公文档、XML、HTML、word文档，邮件，各类报表、图片和音频、视频信息等。\n\n其他的不同之处还有：\n\n结构化数据往往占用的空间较小，占企业数据的 20% 左右，容易管理。\n非结构化数据通常占用更多的存储空间，约占企业数据的 80% 左右，比较难以管理\n\n2，结构化搜索 vs 全文搜索\n结构化搜索：  通常查询具有固有结构的数据，答案要么是肯定的，要么是否定的（即便是类似正则匹配这样的结构化搜索，正则表达式匹配数据也是确定的），数据要么属于查询结果集合，要么不属于。\n全文搜索：  通常查询全文字段&#x2F;文档的所有内容，答案返回的是一系列可能的数据，数据有一定概率属于结果集合。\n\n到这里，为什么需要使用 ES 进行搜索的答案就很明确了：对于非结构化文本（比如评论内容），传统的结构化搜索难以满足需求，于是就会使用 ES 进行全文搜索。当然 ES 不仅可以进行全文搜索，也可以进行一部分的结构化搜索，更加扩大了他的应用范围。对于数据量巨大的情景，有公司会使用 ES 代替传统的 MySQL 管理数据。\nES 基本概念介绍本小结主要是介绍 ES 的一些基本概念，目的是方便之前没有了解过 ES 的同学可以理解这次分享所介绍的内容。\n1，ES 存储模型ES 在设计存储模型时，考虑了大家从关系型数据库转换肯能带来的困难，于是设计了 Index、Type、Document、Field 分别于对应传统关系型数据库(比如 MySQL) 的 Database、Table、Row、Column。注意： ES 存储时，并没有 Type 的概念，同一个Index 里的 Type 会拍平存储，只是方便理解才会对使用者提供这样一个抽象。由于Type 的存在会带来一些问题，在后续的版本里会逐步移除。\n2，ES 与 LuceneES 底层基于 Lucene 开发，Lucene作为其核心来实现索引和搜索的功能。我们虽然讲的是 ES，但很大一部分内容是 Lucene 的实现。​\n","slug":"es-search","date":"2023-03-12T07:19:46.000Z","categories_index":"","tags_index":"elasticsearch","author_index":"Sh1mwww"},{"id":"bee84e518ec4344cb23b6f3015f64773","title":"Goroutine基础","content":"这篇文章将关注 Go 语言基础部分。我们将讨论关于性能方面的一些知识，并通过创建一些简单的 goroutine 来扩展我们的应用程序。\n我们还会关注一些 Go 语言的底层执行逻辑以及 Go 语言与其他语言的不同之处。\nGo 语言的并发继续讨论之前，我们必须理解并发与并行的概念。Golang 可以实现并发和并行。\n我们一起来看下并发与并行的区别。\n理解并发应用程序可能会通过处理多个进程来完成预期的功能。我们来假设一个简单的电子商务网站，经评估有下列需要并发执行的任务：\n\n在网页的顶部显示最新的交易和产品信息；\n显示网站当前的在线用户数量；\n当用户选择商品之后更新购物车详情；\n为“目标交易额”倒计时；\n\n该网站需要同时运行所有这些任务，以使用户与网站保持关联，并使网站对用户有吸引力并吸引更多业务。\n因此，为了满足业务需要，一个简单的应用程序或者网站都可能包含一组后台运行的任务。\n上图所示的两个示例中，有多个任务同时执行，但是它们之间仍然有区别。让我们进一步研究以便能更了解。\n理解并发与并行执行\n\n处理并发应用假设这样一种场景，我们有一台单核机器，需要完成多个任务，但有个限制，在任何时刻，单核机器上只能运行一个任务。\n在并发模型中，任务之间存在上下文切换。该程序正在处理多个任务，但由于我们只有单核，因此任务无法一起执行。\n任务之间的上下文切换很快，以至于我们感觉任务是同时运行的。\n在执行过程中没有并行执行的因素，因为是一个单核系统，多进程不能并行执行。\n如上图所示，Concurrency (Without Parallelism) 有两个任务需要并发执行。在任何时候，只有一个任务在运行并且任务之间存在上下文切换。\n应用程序加入并行使用单核的情况下，存在核数限制。如果我们给机器增加核数，就可以在不同的内核上同时执行任务。\n在上图中(Parallelism)，任一时刻都有两个任务在执行，这两个任务运行在不同的内核上。\n并发是某一时间段内同时处理多个任务，并行是在某一时间点能执行多个任务。\n使用 Go 语言可以轻松地将程序从并发扩展为并行执行。\n使用协程使用 Go 语言实现并发和并行，我们需要了解协程(Goroutines)的概念。Go 语言的协程可以理解为线程之上的一个包装器，由 Go 运行时管理而不是操作系统。\nGo 运行时负责给协程分配和回收资源，协程与完成多任务的线程非常相似但又比操作系统线程消耗更少的资源。协程与线程之间并非一对一的关系。\n我们可以将应用程序“拆解”成多个并发任务，这些任务可以由不同的 goroutine 完成，通过这种方式即可实现了 Go 语言并发。\n协程的优点：\n\n更轻量级；\n易扩展；\n虚拟线程；\n需要更少的初始内存(2KB)；\n有必要的话，Go 运行时能分配更多的内存；一起来看下一个简单的例子：package main\n\nimport (\n    &quot;fmt&quot;\n    &quot;time&quot;\n)\n\nfunc main() &#123;\n  start :&#x3D; time.Now()\n  func() &#123;\n    for i:&#x3D;0; i &lt; 3; i++ &#123;\n      fmt.Println(i)\n    &#125;\n  &#125;()\n\n  func() &#123;\n    for i:&#x3D;0; i &lt; 3; i++ &#123;\n      fmt.Println(i)\n    &#125;\n  &#125;()\n\n  elapsedTime :&#x3D; time.Since(start)\n\n  fmt.Println(&quot;Total Time For Execution: &quot; + elapsedTime.String())\n\n  time.Sleep(time.Second)\n&#125;\n上面的代码按顺序依次在 main 函数里面执行了两个独立函数。\n\n代码没有使用协程，程序在同一个线程中执行完成。程序没有任何的并发性，执行结果如下：代码按顺序执行，从主函数开始，先执行第一个函数，再执行第二个函数，最后从主函数正常退出。\n引入协程上面的场景例子中没有使用任何的协程。我们可以在执行函数之前使用 go 关键字开启协程。\n依旧是上面的例子，我们一起来看看使用 go 关键字开启协程之后会是什么样的：\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;time&quot;\n)\n\nfunc main() &#123;\n  start :&#x3D; time.Now()\n  go func() &#123;\n    for i:&#x3D;0; i &lt; 3; i++ &#123;\n      fmt.Println(i)\n    &#125;\n  &#125;()\n\n  go func() &#123;\n    for i:&#x3D;0; i &lt; 3; i++ &#123;\n      fmt.Println(i)\n    &#125;\n  &#125;()\n\n  elapsedTime :&#x3D; time.Since(start)\n\n  fmt.Println(&quot;Total Time For Execution: &quot; + elapsedTime.String())\n\n  time.Sleep(time.Second)\n&#125;\n执行上面的代码输出：\n上面的代码，使用 go 关键字分别开启了两个协程并执行各自的函数，包括主协程，总共有 3 个协程。\n理解与顺序执行的不同上面的代码，我们使用 go 关键字开启协程，函数会在协程中完成执行，而不是在主协程中执行，这样增加了并发并提高了程序性能。\n增加并行性\n\nGo 语言里，可以通过下面这行简单的代码设置程序运行的内核数目(PS:从 Go 1.5开始，Go 的 GOMAXPROCS 默认值已经设置为 CPU 的核数)。\nruntime.GOMAXPROCS(4)\n这可以指定程序在多核机器上运行，上面一行代码指定程序可以使用四个内核来执行。\n一旦创建了协程，便可以在不同的内核中执行，从而实现并行并加快程序执行速度。\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;time&quot;\n    &quot;runtime&quot;\n)\n\nfunc main() &#123;\n  runtime.GOMAXPROCS(4)\n  start :&#x3D; time.Now()\n  go func() &#123;\n    for i:&#x3D;0; i &lt; 3; i++ &#123;\n      fmt.Println(i)\n    &#125;\n  &#125;()\n\n  go func() &#123;\n    for i:&#x3D;0; i &lt; 3; i++ &#123;\n      fmt.Println(i)\n    &#125;\n  &#125;()\n\n  elapsedTime :&#x3D; time.Since(start)\n\n  fmt.Println(&quot;Total Time For Execution: &quot; + elapsedTime.String())\n\n  time.Sleep(time.Second)\n&#125;\n上面的代码输出如下：使用 Go 语言可以轻松实现并发和并行。只需在函数之前添加 go 关键字就可以提高程序执行速度。\n","slug":"Goroutine","date":"2023-03-12T07:01:19.000Z","categories_index":"","tags_index":"golang","author_index":"Sh1mwww"},{"id":"30d936a7afc35294893d61738d3f7081","title":"Springboot 实现 ES-SQL 的流程","content":"背景记录一个最近半年犯了两次的低级编码错误，校验某个字符串信息为枚举类的某实例时，写成了：枚举类的实例.equals(字符串) ，结果总是 false  ，打印信息貌似正确，实际执行结果总是不达预期，仔细看看代码才发现问题。本文记录本周开发工作中遇到的几个小问题，Bug 是无法完全消除的，只能尽量减少。\nES 连接及时关闭查看某进程的端口占用时，看到好多正连接着的 ES 连接对象，普通的 Java Web 应用，没有后台任务，怎么会保持这么多连接呢？\n问题分析：代码有缺陷，有些请求使用 ES 进行数据查询完成后，没有关闭 ES 连接对象。ES 连接不关闭，有什么问题呢？\nLinux 的每个连接都会创建一个文件句柄，毫无疑问，Socket 连接用完后不关闭，会导致端口资源泄漏。\njackson 序列化异常在将 ElasticSearch 的 Response 对象序列化时碰到一个异常信息：\nCaused by: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class org.elasticsearch.common.text.Text and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.elasticsearch.action.search.SearchResponse[&quot;hits&quot;]-&gt;org.elasticsearch.search.SearchHits[&quot;hits&quot;]-&gt;org.elasticsearch.search.SearchHit[0]-&gt;org.elasticsearch.search.SearchHit[&quot;shard&quot;]-&gt;org.elasticsearch.search.SearchShardTarget[&quot;nodeIdText&quot;])\n有两种解决办法：\n\n定义一个配置类，设置 jackson 的序列化配置属性。\n通过 SpringBoot 的全局配置 spring.jackson.serialization.FAIL_ON_EMPTY_BEANS 设置为 false ，该配置默认为 true，这个方式更方便。\n\nElasticSearch 执行 SQL 的 Java 实现回到文章标题说的问题，ElasticSearch 6 以后的版本支持 SQL 语句检索了，如何用 Java 代码实现 ES SQL 检索呢？\n第一 Part，基础知识。先搞明白需求及相关的技术支持，主要如下：\n\nElasticSearch-SQL 功能，区分 GitHub 上的一个插件和 ElasticSearch 自身的支持能力。ES 6 以后内置了X-Pack 组件，提供了  Elasticsearch SQL 能力，就是说不用安装插件就可以使用 ES SQL 能力了。而网上很多都是介绍 ElasticSearch SQL 插件安装的，却不曾想 ES 已经内置了。\nES 6 与 ES 8 的 Rest API 的语法不一样，8 以上的版本语句是 /_xpack/_sql?format= ，但是旧版本是 /_xpack/sql?format= ，版本依赖问题有时候挺坑的。网上大量的资料，估计都是来自官网，全都是 /_xpack/_sql?format=，结果我测试用的环境是 ES6 的，一直报错。\n\n第二 Part， Java 实现 ES-SQL 操作的几种方法：\n\nRest API 请求 /_xpack/sql?format=。\n*JDBC-ES ，这个功能是收费的。\n\n第三 Part，使用 elasticsearch-rest-high-level-client 包的 RestAPI 客户端工具可以实现 ES-SQL 的操作。基本思路是构建一个 RestClient 对象，请求路径为   /_xpack/_sql?format=json 这个用 txt 的时候，总是得不到结果，用 json 就没问题。\n重要源代码如下：\n&#x2F;&#x2F; ES 连接信息构造\nRestClientBuilder restClientBuilder  &#x3D; null;\nif (hasPwd) &#123;\n\tfinal CredentialsProvider credentialsProvider &#x3D; new BasicCredentialsProvider();\n\t\n\t&#x2F;** 设置 ES 认证信息 *&#x2F;\n    credentialsProvider.setCredentials(AuthScope.ANY,new UsernamePasswordCredentials(userName, password));\n\trestClientBuilder &#x3D; RestClient.builder(https)\n                    .setHttpClientConfigCallback(httpAsyncClientBuilder -&gt; httpAsyncClientBuilder.setDefaultCredentialsProvider(credentialsProvider));\n&#125; else &#123;\n  \trestClientBuilder &#x3D; RestClient.builder(https)\n&#125;\n\n&#x2F;&#x2F; xpack-sql 请求构造\nString searchIndex &#x3D; &quot;&#x2F;_xpack&#x2F;sql?format&#x3D;json&quot;;\nRequest request &#x3D; new Request(&quot;POST&quot;, searchIndex);\nrequest.setJsonEntity(queryJsonString);\n\nRestClient restClient &#x3D; restClientBuilder.build();\ntry &#123;\n    Response response &#x3D; restClient.performRequest(request);\n    String body &#x3D; EntityUtils.toString(response.getEntity());\n    &#x2F;&#x2F; TODO 处理 ES 响应结果\n&#125; catch (IOException e) &#123;\n&#125;\n\nToDesk 服务占据高 CPU电脑一直占据大量的 CPU，top 看是 ToDesk 进程，执行下面的操作好了：\nsudo launchctl unload &#x2F;Library&#x2F;LaunchDaemons&#x2F;com.youqu.todesk.service.plist\n我碰到的问题，绝对不是个例，百度是个好东西，面向百度编程也没什么不好啊！\n","slug":"SpringBootES","date":"2023-03-11T09:47:46.000Z","categories_index":"","tags_index":"Springboot,elasticsearch","author_index":"Sh1mwww"},{"id":"4783a03c76b99864e7fb550cfa766073","title":"Git Flow 工作原理","content":"一、 Git Flow 工作模型的原理无规矩不成方圆，但是规矩太多了，则感觉到束缚。我们一个人工作的时候喜欢无拘无束，想怎么干就怎么干，没有人评判，没有人检验。时间久了就会盲目自大，以为增删改查熟悉业务就能够搞定一些。但是当项目逐渐扩大，原来的灵活逐渐变成了混乱，原来的快速迭代因为过于随意的代码，而开发进度迟迟不前。掌握一种规范，便在处理类似问题的时候有章可循，也能够快速的融入一个团队。另外所谓规范，可以说是比较好的实践，按照规范来，项目也能稳健的发展。\nGit Flow 就是如何使用git 分支的一种规范，或者叫做推荐。\n根据Git Flow 的推荐，我们要将Git 的分支分为 master 、develop 、hotfix 、release、feature这五个分支。各种分支分别负责不同的功能，平时开发的时候各司其职，因此会有比较小的冲突率。那么可以用这些减少冲突的时间，少加会班，多有点自己的生活岂不快哉。一图胜千言：\n\n\nmaster 分支master 分支主要方稳定、随时可上线的版本。这个分支只能从别的分支上合并过来，一般来讲，从develop 上合并，或者从bugfix 分支上合并过来。不能直接在master 分支上进行commit文件。因为是稳定的版本，所以每次版本发布都要在这个分支上添加标签(tag)。\ndevelop 分支develop 分支是所有开发分支的母体，所有的开发分支都要从develop上切出来，开发完成之后最后都要合并到develop上。\nhotfix 分支hotfix 分支用来修复生产中的紧急bug，由于develop分支尚处于开发过程中，代码不稳定，不能直接应用于生产。所以从master分支上切出一个分支，修复完成之后合并到master分支，并且合并到develop上。\nrelease 分支release 分支可以称之为预发布的版本。当我们认为develop版本的代码已经趋于成熟，我们可以打一个release分支。在release 分支上测试完成之后，要将代码合并到master分支和develop上。master 分支是线上版本，而合并到develop版本是因为，在测试过程中，一些细节的东西可能会修改，因此这些优化的内容也应该合并到最终版本以及开发版本中。\nfeature 分支feature 分支是最经常使用的分支了。当我们收到一个新的开发功能时，应该在develop分支上切出一个feature分支。用来完成新功能的开发，开发完成之后，要合并进develop分支上。\n二、 Git Flow 工具的使用基本上各种git的客户端软件都会支持Git Flow 工作模型。sourcetree 上使用git flow 工作模型就很流畅，体验很好。但是为了全平台上通用，以及理解原理，快速上手。我们来学习下Git Flow 的命令行操作。\ngit flow 是一种git的使用规范，当然也有相应的工具集，命令行命令让我们使用。\n\n\n1、起步安装git flow\nbrew install git-flow-avh\n初始化git flow 工具库\ngit flow init\n之后都按照默认的去配置，直接按enter键继续。\n2、feature 分支操作增加feature新特性分支\ngit flow feature start your roverliang&#x2F;addlist\n示例:\nroverliang$ git flow feature start roverliang&#x2F;addlist\nSwitched to a new branch &#39;feature&#x2F;roverliang&#x2F;addlist&#39;\n\nSummary of actions:\n- A new branch &#39;feature&#x2F;roverliang&#x2F;addlist&#39; was created, based on &#39;develop&#39;\n- You are now on branch &#39;feature&#x2F;roverliang&#x2F;addlist&#39;\n\nNow, start committing on your feature. When done, use:\n\n     git flow feature finish roverliang&#x2F;addlist\n\nroverliang$ git branch\n  develop\n* feature&#x2F;roverliang&#x2F;addlist\n  master\n完成新特性这个动作执行的是下面的流程:\n\n合并 addlist 分支到 develop\n删除这个新特性分支\n切换回 develop 分支git flow feature finish roverliang&#x2F;addlist\n\n示例：\nroverliang$ git flow feature finish roverliang&#x2F;addlist\nSwitched to branch &#39;develop&#39;\nYour branch is up to date with &#39;origin&#x2F;develop&#39;.\nAlready up to date.\nDeleted branch feature&#x2F;roverliang&#x2F;addlist (was 2e1b475).\n\nSummary of actions:\n- The feature branch &#39;feature&#x2F;roverliang&#x2F;addlist&#39; was merged into &#39;develop&#39;\n- Feature branch &#39;feature&#x2F;roverliang&#x2F;addlist&#39; has been locally deleted\n- You are now on branch &#39;develop&#39;\n\nroverliang$ git branch\n* develop\n  master\nroverliang$\n获取一个发布的新特性的分支\ngit flow feature track origin MYFEATURE\n\n3、release 分支操作准备release 版本\ngit flow release start RELEASE [BASE]\n\n你可以选择提供一个 [BASE]参数，即提交记录的 sha-1 hash 值，来开启动 release 分支. 这个提交记录的 sha-1 hash 值必须是&#39;develop&#39; 分支下的。\n\n示例：\nroverliang$ git branch\n  develop\n  feature&#x2F;test\n* master\nroverliang$ git log --pretty&#x3D;oneline -3\n2e1b475f9825275aefa0892cfe5259aaac9a3483 (HEAD -&gt; master, origin&#x2F;test2, origin&#x2F;master, origin&#x2F;feature&#x2F;test, origin&#x2F;develop, feature&#x2F;test, develop) delte some content\n2d22f306d2dca363b8aaa05743be342a505aabb0        renamed:    demo.txt -&gt; test.txt\nfbf025e210952c3cdb10e219c4ee5f82b9f36327        modified:   demo.txt\nroverliang$\n\n发布release 版本\ngit flow release track RELEASE\n\n完成release 版本 相当于执行以下几个动作：\n\n归并 release 分支到 ‘master’ 分支\n用 release 分支名打 Tag\n归并 release 分支到 ‘develop’\n移除 release 分支git flow release finish RELEASE\n\n4、bugfix 分支操作紧急修复的需求：\n\n紧急修复来自这样的需求：生产环境的版本处于一个不预期状态，需要立即修正。\n有可能是需要修正 master 分支上某个 TAG 标记的生产版本。\n\n开始紧急修复，开启hotfix 分支\ngit flow hotfix start VERSION [BASENAME]\nVERSION 参数标记着修正版本。你可以从 [BASENAME]开始，[BASENAME]为finish release时填写的版本号\n\n完成紧急修复:当完成紧急修复分支，代码归并回 develop 和 master 分支。相应地，master 分支打上修正版本的 TAG。\ngit flow hotfix finish VERSION","slug":"gitflow intro","date":"2023-03-11T08:13:35.000Z","categories_index":"","tags_index":"gitflow","author_index":"Sh1mwww"},{"id":"90bb244b78e2bf4cc75c96413958b4eb","title":"ElasticSearch数据库简单介绍","content":"elasticsearch简介ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。\nelasticSearch的使用场景1、为用户提供按关键字查询的全文搜索功能。2、实现企业海量数据的处理分析的解决方案。大数据领域的重要一份子，如著名的ELK框架(ElasticSearch,Logstash,Kibana)。\n与其他数据存储进行比较\n\nelasticsearch的特点\n天然分片，天然集群  es 把数据分成多个shard，下图中的P0-P2，多个shard可以组成一份完整的数据，这些shard可以分布在集群中的各个机器节点中。随着数据的不断增加，集群可以增加多个分片，把多个分片放到多个机子上，已达到负载均衡，横向扩展。在实际运算过程中，每个查询任务提交到某一个节点，该节点必须负责将数据进行整理汇聚，再返回给客户端，也就是一个简单的节点上进行Map计算，在一个固定的节点上进行Reduces得到最终结果向客户端返回。\n\n天然索引  ES 所有数据都是默认进行索引的，这点和mysql正好相反，mysql是默认不加索引，要加索引必须特别说明，ES只有不加索引才需要说明。而ES使用的是倒排索引和Mysql的B+Tree索引不同。\n\n\n传统关系性数据库\n弊端：\n\n对于传统的关系性数据库对于关键词的查询，只能逐字逐行的匹配，性能非常差。\n*匹配方式不合理，比如搜索“小密手机” ，如果用like进行匹配， 根本匹配不到。但是考虑使用者的用户体验的话，除了完全匹配的记录，还应该显示一部分近似匹配的记录，至少应该匹配到“手机”。倒排索引是怎么处理的全文搜索引擎目前主流的索引技术就是倒排索引的方式。传统的保存数据的方式都是记录→单词而倒排索引的保存数据的方式是单词→记录\n\n索引结构对比可以看到 lucene 为倒排索引(Term Dictionary)部分又增加一层Term Index结构，用于快速定位，而这Term Index是缓存在内存中的，但mysql的B+tree不在内存中，所以整体来看ES速度更快，但同时也更消耗资源（内存、磁盘）。\nlucene与elasticsearch的关系咱们之前讲的处理分词，构建倒排索引，等等，都是这个叫lucene的做的。那么能不能说这个lucene就是搜索引擎呢？\n还不能。lucene只是一个提供全文搜索功能类库的核心工具包，而真正使用它还需要一个完善的服务框架搭建起来的应用。\n好比lucene是类似于发动机，而搜索引擎软件（ES,Solr）就是汽车。\n目前市面上流行的搜索引擎软件，主流的就两款，elasticsearch和solr,这两款都是基于lucene的搭建的，可以独立部署启动的搜索引擎服务软件。由于内核相同，所以两者除了服务器安装、部署、管理、集群以外，对于数据的操作，修改、添加、保存、查询等等都十分类似。就好像都是支持sql语言的两种数据库软件。只要学会其中一个另一个很容易上手。\n从实际企业使用情况来看，elasticSearch的市场份额逐步在取代solr，国内百度、京东、新浪都是基于elasticSearch实现的搜索功能。国外就更多了 像维基百科、GitHub、Stack Overflow等等也都是基于ES的。\n","slug":"elk","date":"2023-03-05T07:57:17.000Z","categories_index":"","tags_index":"elasticsearch","author_index":"Sh1mwww"},{"id":"d4105a7b8a6b6b0d8864aefbdb368e9a","title":"mylover","content":"tags:    mylover兴趣广泛，喜欢篮球足球hiphop\n","slug":"mylover","date":"2022-04-15T07:42:17.000Z","categories_index":"","tags_index":"","author_index":"Sh1mwww"},{"id":"bccecdef4d85db8990deae967274cbf8","title":"myfirstblog","content":"简单的简介这是我的第一个blog，一个简单的hexo框架构成的网站\nSh1mwww本人很懒。不会定期更新使用","slug":"myfirstblog","date":"2022-04-15T07:41:44.855Z","categories_index":"","tags_index":"","author_index":"Sh1mwww"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-04-04T08:45:44.257Z","categories_index":"","tags_index":"","author_index":"Sh1mwww"}]